\chapter{Случайные величины}

\section{Сформулировать определение случайной величины и функции распределения вероятностей случайной величины. Доказать свойства функции распределения.}

Пусть $(\Omega, \beta, P)$ -- вероятностное пространство некоторого случайного эксперимента.

\textbf{Случайной величиной} называется функция $X: \Omega \rightarrow \mathbb{R}$ такая, что $\forall x \in \mathbb{R}: \{\omega: X(\omega) < x\} \in \beta$.

\textbf{Функцией распределения вероятностей случайной величины} $X$ называется отображение $F_X:~\mathbb{R}\rightarrow\mathbb{R}$, определенное правилом $F_X(x) = P\{X < x\}$.

\subsection*{Свойства функции распределения}
\begin{enumerate}
	\item $0 \leq F(x) \leq 1$.
	
		\textbf{Доказательство.} $F(x)$ определена как вероятность, т.е. $F(x) = P\{...\} \in [0; 1]$.
		
	\item $F$ -- неубывающая функция, т.e. если $x_1 \leq x_2$, то $F(x_1) \leq F(x_2).$
	
		\textbf{Доказательство.} Если $x_1 \leq x_2$, тогда $F(x_2) = P\{X < x_2\} = P\{\underbrace{\{X < x_1\}}_\text{Событие $A$} + \underbrace{\{x_1 \leq X < x_2\}}_\text{Событие $B$}\}$. События $A$ и $B$ несовместны $\Rightarrow F(x_2) = P\{\underbrace{\{X < x_1\}}_\text{$F(x_1)$} + \underbrace{\{x_1 \leq X < x_2\}}_\text{$\geq0$}\} \geq F(x_1)$.  
	
	\item  $\lim\limits_{x \rightarrow -\infty}F(x) = 0$; $\lim\limits_{x \rightarrow +\infty}F(x) = 1$.
	
		\textbf{Доказательство.} Рассмотрим последовательность $x_1, x_2, x_3,...$ такую, что 
		
		(a) $x_1 < x_2 < x_3 < ...$; 
		
		(b) $\lim\limits_{i \rightarrow \infty} x_i = +\infty$.
		
		$A_i = \{X < x_i\}, i \in \mathbb{N}$; $A_1 \subseteq A_2 \subseteq ... \subseteq A_n \subseteq A_{n+1} \subseteq ...$ -- неубывающая последовательность событий. $\Rightarrow \lim\limits_{x \rightarrow \infty} F(x_i) = \lim\limits_{i \rightarrow \infty} P(A_i) = |\text{аксиома непрерывности}| = P\{X < +\infty\} = 1$.
		
		Т.к. $x_1, x_2, x_3,...$ -- произвольная последовательность (неубывающая и стремящаяся к бесконечности), то в соответствии с определением предела функции по Гейне $\lim\limits_{x \rightarrow +\infty}F(x) = 1$. Вторая часть этого свойства доказывается аналогично.
		
	\item $\lim\limits_{x \rightarrow x_0-}F(x) = F(x_0)$, в каждой точке $F$ непрерывна слева.
		
		\textbf{Доказательство.} Пусть $x_1,x_2,...$ -- возрастающая последовательность, $\lim\limits_{i \rightarrow \infty}x_i = x_0$.
		
		Пусть $A_i = \{X < x_i\}, i \in \mathbb{N}$. Тогда событие $\{X < x_i\} = \bigcup_{i=1}^\infty A_i$, причем последовательность событий $A_1,A_2,...$ является возраставющей $\Rightarrow \lim\limits_{i \rightarrow \infty} F(x_i) = \lim\limits_{i \rightarrow \infty} P(A_i) = |\text{аксиома непрерывности}|=P\{X<x_0\} = F(x_0)$. Т.к. $x_1, x_2,...$ - произвольная последовательность, сходящаяся к $x_0$ слева, то в соответствии с определением предела функции по Гейне $\lim\limits_{x \rightarrow x_0-} F(x) = F(x_0)$.
		
	\item $P\{a \leq X < b\} = F(b) - F(a)$.
	
		\textbf{Доказательство.} $\{X < b\} = \{X < a\} + \{a \leq X < b\} \Rightarrow \underbrace{P\{X < b\}}_\text{$F(b)$} = \underbrace{P\{X < a\}}_\text{$F(a)$} +$\newline $+P\{a \leq X < b\} \Rightarrow P\{a~\leq~X~<~b\}~=~F(b) - F(a)$.
\end{enumerate}

\section{Сформулировать определения случайной величины и функции распределения случайной величины. Сформулировать определения дискретной и непрерывной случайной величины. Доказать свойства плотности распределения вероятностей непрерывной случайной величины.}

Пусть $(\Omega, \beta, P)$ -- вероятностное пространство некоторого случайного эксперимента.

\textbf{Случайной величиной} называется функция $X: \Omega \rightarrow \mathbb{R}$ такая, что $\forall x \in \mathbb{R}: \{\omega: X(\omega) < x\} \in \beta$.

\textbf{Функцией распределения вероятностей случайной величины} $X$ называется отображение $F_X:~\mathbb{R}\rightarrow\mathbb{R}$, определенное правилом $F_X(x) = P\{X < x\}$.

Случайная величина называется \textbf{дискретной}, если множество её значений конечно или счётно.

Случайная величина $X$ называется \textbf{непрерывной}, если существует функция $f(x): \mathbb{R} \rightarrow \mathbb{R}$ такая, что $\forall x \in \mathbb{R}: F(x) = \int_{-\infty}^{x}f(t)dt$ ($F$ -- функция распределения вероятностей случайной величины $X$). При этом $f$ называют функцией плотности распределения вероятности случайной величины $X$.

\subsection*{Cвойства плотности распределения вероятностей}
\begin{enumerate}
	\item $f(x) \geq 0$.
	
		\textbf{Доказательство.} $F$ -- неубывающая функция $\Rightarrow f(x) = F^\text{'}(x) \geq 0$.
	
	\item $P\{a \leq X < b\} = \int_{a}^{b}f(x)dx$.
	
		\textbf{Доказательство.} $P\{x \leq X < b\} = F(b) - F(a) = [f(x)=F^\text{'}(x); \text{по формуле Ньютона--Лейбница}] = \text{$=$}\int_{a}^{b}f(x)dx$. 
	
	\item $\int_{-\infty}^{+\infty}f(x)dx = 1$.
	
		\textbf{Доказательство.} $\int_{-\infty}^{+\infty}f(x)dx = \lim\limits_{\substack{x_1 \rightarrow -\infty \\ x_2 \rightarrow +\infty}} \int_{x_1}^{x_2}f(x)dx = |\text{свойство 2}| = \lim\limits_{x_2 \rightarrow +\infty}F(x_2) - \lim\limits_{x_1 \rightarrow -\infty}F(x_1) =$ $=F(+\infty)-F(-\infty)=1-0=1$.
	
	\item $P\{x_0 \leq X < x_0 + \Delta x\} \approx f(x_0)\Delta x$; $x_0$ -- точка непрерывности функции $f$, $\Delta x$ -- мало.
	
		\textbf{Доказательство.} $P\{x_0 \leq X < x_0 + \Delta x\} = |\text{свойство 2}| = F(x_0 + \Delta x) - F(x_0)$. Т.к. $x_0$ -- точка непрерывности $f$, а $\Delta x$ -- мало, то можно считать, что в окрестности $(x_0, x_0 + \Delta x)$ функция $F^\text{'} = f$ непрерывна. Применим к функции $f$ на $[x_0, x_0 + \Delta x]$ т. Лагранджа $F(x_0 + \Delta x) - F(x_0) = \underbrace{F^\text{'}(\xi)}_\text{$f(\xi)$}\Delta x$, где $\xi \in (x_0, x_0 + \Delta x)$. Т.к. $\Delta x$ мало, а $f$ непрерывна в некоторой окрестности $x_0$, то можно считать, что $f(\xi) \approx f(x_0)$. Таким образом, $P\{x_0 \leq X < x_0 + \Delta x\} \approx f(x_0)\Delta x$.
	
	\item Для любого наперед заданного $x_0 \in \mathbb{R}$: $P\{X = x_0\} = 0$.
	
		\textbf{Доказательство.} $P\{X=x_0\}=\lim\limits_{\Delta x \rightarrow 0} P\{x_0 \leq X < x_0 + \Delta x\} = \lim\limits_{\Delta x \rightarrow 0}[F(x_0 + \Delta x) - F(x_0)] = 0$, т.к. $F$ -- непрерывна.
		
\end{enumerate}

\section{Сформулировать определение нормальной случайной величины, указать геометрический смысл параметров. Понятие стандартного нормального закона. Доказать формулу для вычисления вероятности попадания нормальной случайной величины в интервал.}

Говорят, что случайная величина $X$ имеет \textbf{нормальное распределение} с параметрами $m$ и $\sigma^2 (\sigma > 0)$, если её функция плотности имеет вид $f(x) = \frac{e^{-\frac{(x-m)^2}{2\sigma^2}}}{\sigma\sqrt{2\pi}}, x \in \mathbb{R}$. Обозначается $X \sim N(m, \sigma^2)$.


\begin{figure}[ht!]
	\begin{minipage}{0.4\textwidth}
		\begin{tikzpicture}
			\begin{axis}[domain=-5:5, width=10cm, height=5cm, grid, xlabel={$x$}, ylabel={$f(x)$}]
				\addplot[blue, thick, samples=100] {exp(-((x-0)^2)/(2*(0.5)^2))/(0.5*sqrt(2*pi))};
				\addplot[red, thick, samples=100] {exp(-((x-0)^2)/(2*(1)^2))/(1*sqrt(2*pi))};
				\addplot[green, thick, samples=100] {exp(-((x-0)^2)/(2*(2)^2))/(2*sqrt(2*pi))};
				\legend{$\sigma = 0.5$, $\sigma = 1$, $\sigma = 2$}
			\end{axis}
		\end{tikzpicture}
	\end{minipage}%
	\hfill
	\begin{minipage}{0.45\textwidth}
		Функция плотности нормального распределения имеет характерную колоколообразную форму; $m$ является координатой $x$ <<центра>> этого колокола (центра симметрии), а $\sigma$ характеризует разброс значений случайной величины; чем меньше $\sigma$, тем выше экстремум функции плотности.
	\end{minipage}
\end{figure}

Распределение $N(0, 1)$ называет \textbf{стандартным нормальным распределением}; для него функция плотности равна $f(x) = \frac{e^{-\frac{x^2}{2}}}{\sqrt{2\pi}}, x \in \mathbb{R}$.

\subsection*{Формула для вычисления вероятности попадания нормальной случайной величины в интервал.}

Рассмотрим
\[
P\{a \leq X < b\} = \Bigl\langle \text{по свойству плотности распределения} \Bigr\rangle =
\int_a^b f_X(x) \, dx = \int_a^b \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x - m)^2}{2\sigma^2}} \, dx =
\]
\[
= \Bigl\langle t = \frac{x - m}{\sigma}, \, dx = \sigma \, dt; \, x = a \implies t = \frac{a - m}{\sigma}, \, x = b \implies t = \frac{b - m}{\sigma} \Bigr\rangle =
\]
\[
= \int_{\frac{a-m}{\sigma}}^{\frac{b-m}{\sigma}} \frac{1}{\sqrt{2\pi}} e^{-\frac{t^2}{2}} \, dt = \Bigl\langle \Phi(t) = \int_{-\infty}^t f_{0,1}(t) \, dt \Bigr\rangle =
\]
\[
= \Phi\left(\frac{b - m}{\sigma}\right) - \Phi\left(\frac{a - m}{\sigma}\right) = \Bigl\langle \Phi(t) \text{ — стандартное нормальное распределение, такое, что }
\]
\[
\Phi(0) = \frac{1}{2} \implies \Phi(t) \Bigr\rangle = \Phi_0\left(\frac{b - m}{\sigma}\right) - \Phi_0\left(\frac{a - m}{\sigma}\right).
\]

Т.к. \( X \sim N(m, \sigma^2) \) -- непрерывная случайная величина, то
\[
P\{a \leq X \leq b\} = \Phi_0\left(\frac{b - m}{\sigma}\right) - \Phi_0\left(\frac{a - m}{\sigma}\right) = \Phi\left(\frac{b - m}{\sigma}\right) - \Phi\left(\frac{a - m}{\sigma}\right).
\]

\section{Сформулировать определение случайного вектора и функции распределения вероятностей случайного вектора. Сформулировать свойства функции распределения двумерного случайного вектора. Доказать предельные свойства.}

Пусть: 
\begin{enumerate}
	\item $(\Omega, \beta, P)$ -- вероятностное пространство.
	
	\item $X_{\omega} = X_1(\omega),...,X_n(\omega)$ -- случайные величины, заданные на этом вероятностном пространстве.
\end{enumerate}
Тогда $n$-мерным \textbf{случайным вектором} называется кортеж $\vec{X} = (X_1,..., X_n)$.

\textbf{Функцией распределения вероятностей случайного вектора} называют отображение $F: \mathbb{R}^n \rightarrow \mathbb{R}$, определенное правилом $F(x_1, ..., x_n) = P\{X_1 < x_1,..., X_n < x_n\}$.

\subsection*{Свойства}
\begin{enumerate}
	\item $0 \leq F(x_1, x_2) \leq 1$.
	
	\item (a) При фиксированном $x_2$ функция $F(x_1, x_2)$ как функция переменного $x_1$
	является неубывающей функцией;
	
	(b) При фиксированном $x_1$ функция $F(x_1, x_2)$ как функция переменного $x_2$
	является неубывающей функцией;
	
	\item $\quad \lim\limits_{\substack{x_1 \to -\infty \\ x_2 = \text{const}}} F(x_1, x_2) = 0, \quad \lim\limits_{\substack{x_1 = \text{const} \\ x_2 \to -\infty}} F(x_1, x_2) = 0$.
	
		\textbf{Доказательство.} По определению, \( F(x_1, x_2) = P(\{X_1 < x_1\} \cdot \{X_2 < x_2\}) \); при \( x_1 \to -\infty \) событие \(\{X_1 < -\infty\}\) является невозможным. Произведение невозможного события на событие \(\{X_2 < x_2\}\) является невозможным событием, поэтому \( F(x_1, x_2) \) стремится к нулю при \( x_1 \to -\infty, \, x_2 = \text{const} \).
		
		$
		\lim\limits_{\substack{x_1 = \text{const} \\ x_2 \to -\infty}} F(x_1, x_2) = 0
		$ доказывается аналогично.
	
	\item $\quad \lim\limits_{\substack{x_1 \to +\infty \\ x_2 \to +\infty}} F(x_1, x_2) = 1.$.
	
		\textbf{Доказательство.} По определению, \( F(x_1, x_2) = P(\{X_1 < x_1\} \cdot \{X_2 < x_2\}) \). Событие $\{X_1 < +\infty\}$ является достоверным, $\{X_2 < +\infty\}$ также является достоверным, а произведение достоверных событий -- достоверное событие.
		
	\item $\quad \lim\limits_{{\substack{x_1 \to +\infty \\ x_2 = \text{const}}}} F(x_1, x_2) = F_{X_2}(x_2), \quad \lim\limits_{\substack{x_1 = \text{const} \\ x_2 \to +\infty}} F(x_1, x_2) = F_{X_1}(x_1)$, 
	
	где $F_{X_i}$ -- маргинальная функция распределения случайной величины $X_i$.
	
		\textbf{Доказательство.} По определению, \( F(x_1, x_2) = P(\{X_1 < x_1\} \cdot \{X_2 < x_2\})\). Событие $\{X_2 < +\infty\}$ является достоверным, следовательно, $\quad \lim\limits_{{\substack{x_1 \to +\infty \\ x_2 = \text{const}}}} F(x_1, x_2) = P\{X_2 < x_2\} = F_{X_2}(x_2)$. 
		
		Для второго предела -- доказывается аналогично.
		
	\item $D = \{(x, y): x \in [a_1, b_1), y \in [a_2, b_2)\}: P{a_1 \leq X < b_1, a_2 \leq Y < b_2} = F(b_1, b_2) - F(a_1, b_2) -$ $-F(a_2, b_1) + F(a_1, a_2)$.
	
	\item (a) При фиксированном $x_2$ функция $F(x_1, x_2)$ как функция переменного $x_1$
	является непрерывной слева в каждой точке;
	
	(b) При фиксированном $x_1$ функция $F(x_1, x_2)$ как функция переменного $x_2$
	является непрерывной слева в каждой точке;
	
\end{enumerate}


\section{Сформулировать определение случайного вектора и функции распределения вероятностей случайного вектора. Сформулировать свойства функции распределения двумерного случайного вектора. Доказать формулу для вычисления $P\{a_1 \leq X_1 < b1, a_2 \leq X_2 < b_2\}$.}

Пусть: 
\begin{enumerate}
	\item $(\Omega, \beta, P)$ -- вероятностное пространство.
	
	\item $X_{\omega} = X_1(\omega),...,X_n(\omega)$ -- случайные величины, заданные на этом вероятностном пространстве.
\end{enumerate}
Тогда $n$-мерным \textbf{случайным вектором} называется кортеж $\vec{X} = (X_1,..., X_n)$.

\textbf{Функцией распределения вероятностей случайного вектора} называют отображение $F: \mathbb{R}^n \rightarrow \mathbb{R}$, определенное правилом $F(x_1, ..., x_n) = P\{X_1 < x_1,..., X_n < x_n\}$.

\subsection*{Свойства}
\begin{enumerate}
	\item $0 \leq F(x_1, x_2) \leq 1$.
	
	\item (a) При фиксированном $x_2$ функция $F(x_1, x_2)$ как функция переменного $x_1$
	является неубывающей функцией;
	
	(b) При фиксированном $x_1$ функция $F(x_1, x_2)$ как функция переменного $x_2$
	является неубывающей функцией;
	
	\item $\quad \lim\limits_{\substack{x_1 \to -\infty \\ x_2 = \text{const}}} F(x_1, x_2) = 0, \quad \lim\limits_{\substack{x_1 = \text{const} \\ x_2 \to -\infty}} F(x_1, x_2) = 0$.
	
	\item $\quad \lim\limits_{\substack{x_1 \to +\infty \\ x_2 \to +\infty}} F(x_1, x_2) = 1.$.
	
	\item $\quad \lim\limits_{{\substack{x_1 \to +\infty \\ x_2 = \text{const}}}} F(x_1, x_2) = F_{X_2}(x_2), \quad \lim\limits_{\substack{x_1 = \text{const} \\ x_2 \to +\infty}} F(x_1, x_2) = F_{X_1}(x_1)$, 
	
	где $F_{X_i}$ -- маргинальная функция распределения случайной величины $X_i$.
	
	\item $D = \{(x, y): x \in [a_1, b_1), y \in [a_2, b_2)\}: P\{a_1 \leq X < b_1, a_2 \leq Y < b_2\} = F(b_1, b_2) - F(a_1, b_2) -$ $-F(a_2, b_1) + F(a_1, a_2)$.
	
	\item (a) При фиксированном $x_2$ функция $F(x_1, x_2)$ как функция переменного $x_1$
	является непрерывной слева в каждой точке;
	
	(b) При фиксированном $x_1$ функция $F(x_1, x_2)$ как функция переменного $x_2$
	является непрерывной слева в каждой точке;
	
\end{enumerate}

\subsection*{Формула для вычисления $P\{a_1 \leq X_1 < b1, a_2 \leq X_2 < b_2\}$}

\begin{enumerate}[label=(\alph*)]
	\item Найдем вероятность попадания случайного вектора $(X_1, X_2)$ в полосу $\{X_1 < x_1, a_2 \leq X < b_2\}$
	
	\begin{enumerate}[label=\arabic*.]
		\item $\{X_1 < x_1, X_2 < b_2\} = \{X_1 < x_1, a_2 \leq X < b_2\} + \{X_1 < x_1, X_2 < a_2\}$
		
		\item По теореме сложения: $P\{X_1 < x_1, X_2 < b_2\} = P\{X_1 < x_1, a_2 \leq X_2 < b_2 \} +$\newline$+P\{X_1 < x_1, X_2 < a_2\} \Rightarrow P\{X_1<x_1,a_2\leq X_2<b_2\} = F(x_1, b_2) - F(x_1, a_2)$.
	\end{enumerate}
	
	\item \begin{enumerate}[label=\arabic*.]
		\item $\{X_1 < b_1, a_2 
		\leq X <b_2\} = \{a_1 \leq X_1 < b_1, a_2 \leq X_2 < b_2\} + \{X_1 < a_1, a_2 \leq X_2 < b_2\}$.
		
		\item По формуле сложения: $P\{X_1 < b_1, a_2 \leq X_2 < b_2\} = P\{a_1 \leq X_1 < b_1, a_2 \leq X_2 < b_2\} +$ 
		\newline$+P\{X_1 < a_1, a_2 \leq X_2 < b_2\} \Rightarrow \text{из пункта (а)}: P\{a_1 \leq X_1 < b1, a_2 \leq X_2 < b_2\} =  F(b_1, b_2) -$ $-F(a_1, b_2)-F(a_2, b_1) + F(a_1, a_2)$.
	\end{enumerate}
	
\end{enumerate}



\section{Сформулировать определение случайного вектора и функции распределения вероятностей случайного вектора. Сформулировть определение непрерывного случайного вектора и доказать свойства плотности распределения вероятностей для двумерного случайного вектора.}

Пусть: 
\begin{enumerate}
	\item $(\Omega, \beta, P)$ -- вероятностное пространство.
	
	\item $X_{\omega} = X_1(\omega),...,X_n(\omega)$ -- случайные величины, заданные на этом вероятностном пространстве.
\end{enumerate}
Тогда $n$-мерным \textbf{случайным вектором} называется кортеж $\vec{X} = (X_1,..., X_n)$.

\textbf{Функцией распределения вероятностей случайного вектора} называют отображение $F: \mathbb{R}^n \rightarrow \mathbb{R}$, определенное правилом $F(x_1, ..., x_n) = P\{X_1 < x_1,..., X_n < x_n\}$.

Случайный вектор $\vec{X} = (X_1,...,X_n)$ называется \textbf{непрерывным}, если существует функция $f: \mathbb{R}^n \rightarrow \mathbb{R}$ такая, что для каждой точки $(x_1,...,x_n)$ выполняется $F(x_1,...,x_n) =$\newline$= \int_{-\infty}^{x_1}dt_1 \int_{-\infty}^{x_2}dt_2 ... \int_{-\infty}^{x_n}f(t_1,...,t_n)dt_n,$ где $F$ -- функция распределения плотности случайного вектора $\vec{X}$. При этом $f$ называется \textbf{функцией плотности распределения вероятностей} этого вектора.

\subsection*{Свойства плотности распределения}
\begin{enumerate}
	\item $f(x_1, x_2) \geq 0$.
	
	\item $P\{a_1\leq X_1 < b_1, a_2 \leq X_2 < b_2\} = \int_{a_1}^{b_1}dx_1\int_{a_2}^{b_2}f(x_1, x_2)dx_2$.
	
	\item $\int\int_{\mathbb{R}^2}f(x_1, x_2)dx_1dx_2=1$.
	
	\item $P\{x_1^0 \leq x_1 < x_1^0 + \Delta x_1, x_2^0 \leq X_2 < x_2^0 + \Delta x_2\} \approx f(x_1^0, x_2^0) \Delta x_1 \Delta x_2$, $(x_1^0, x_2^0)$ -- точка непрерывности функции $f$, $\Delta x_1, \Delta x_2$ достаточно малы. 
		
	\item Для любых наперед заданных $x_1^0, x_2^0: P\{(X_1, X_2) = (x_1^0, x_2^0)\} = 0$.
		
	\item $P\{(X_1, X_2) \in D\} = \int\int_{D}f(x_1, x_2)dx_1dx_2$.
	
	\item $\int_{-\infty}^{+\infty}f(x_1,x_2)dx_2 = f_{X_1}(x_1); \int_{-\infty}^{+\infty}f(x_1,x_2)dx_1 = f_{X_2}(x_2)$, где $f_{X_1}, f_{X_2}$ -- маргинальные функции плотности случайных величин $X_1$ и $X_2$ соответственно.
\end{enumerate}

\subsection*{Доказательства}

Доказательства свойств 1-5 аналогичны одномерному случаю.

Свойство 6 является обобщением свойства 2 на случай произвольной области $D$ (без доказательства).

\textbf{Доказательство свойства 7.}  $F(x_1, +\infty) = F_{X_1}(x_1)$ -- по свойству двумерной функции распределения; таким образом (подставим определение функции распределения для двумерного вектора), $F_{X_1}(x_1) = \int_{-\infty}^{x_1} \int_{-\infty}^{+\infty} f(t_1, t_2) \, dt_2 \, dt_1$.

$f_{X_1}(x_1) = \frac{dF_{X_1}(x_1)}{dx_1} = \Bigl\langle x_1\text{-- точка непрерывности функции $f_{X_1}(x_1)$, и точка по теореме}$ $\text{о производной интеграла с переменным верхним пределом} \Bigl\rangle = \int_{-\infty}^{+\infty}f(t_1, t_2)dt_2$. 

Вторая формула доказывается аналогично.

\section{Сформулировать определение пары независимых случайных величин. Доказать свойства независимых случайных величин. Понятия попарно независимых случайных величин и случайных величин, независимых в совокупности.}

Случайные величины \( X \) и \( Y \) называются независимыми, если
\(F(x, y) = F_X(x) F_Y(y)\), где \( F \) -- совместная функция распределения \( X \) и \( Y \) ($\equiv$ функция распределения случайного вектора \( (X, Y) \)); \( F_X \), \( F_Y \) -- маргинальные функции распределения случайных величин \( X \) и \( Y \).

\subsection*{Свойства независимых случайных величин}
\begin{enumerate}
	\item Случайные величины \( X \) и \( Y \) независимы
	\(\Leftrightarrow \forall x, y \in \mathbb{R}, \ \text{события} \{ X < x \} \ \text{и} \{ Y < y \} \ \text{независимы}
	\).
	
	\textbf{Доказательство.} Очевидно следует из определения независимых случайных величин.
	
	\item Случайные величины \( X \) и \( Y \) независимы
	\(\Leftrightarrow \forall x_1, x_2 \in \mathbb{R}, \ \forall y_1, y_2 \in \mathbb{R}, \ \text{события} \{ x_1 \leq X < x_2 \} \ \text{и}\) \(\{ y_1 \leq Y < y_2 \} \ \text{независимы}
	\).
	
	\textbf{Доказательство.} 
	
	\textbf{(a) Необходимость (\( \Rightarrow \))}.  
	Пусть \( F(x, y) = F_X(x) F_Y(y) \). Тогда
	
	\[
	P\{x_1 \leq X < x_2, \, y_1 \leq Y < y_2\} = 
	\text{(свойство функции распределения случайного вектора)} = 
	\]
	
	\[
	 = F(x_1, y_1) + F(x_2, y_2) - F(x_1, y_2) - F(x_2, y_1) = 
	\]
	
	\[
	= F_X(x_1) F_Y(y_1) + F_X(x_2) F_Y(y_2) - F_X(x_1) F_Y(y_2) - F_X(x_2) F_Y(y_1) = 
	[F_X(x_2) - F_X(x_1)] [F_Y(y_2) - F_Y(y_1)] = 
	\]
	
	\[
	= \text{(свойство одномерной функции распределения)} = 
	P\{x_1 \leq X < x_2\} P\{y_1 \leq Y < y_2\}.
	\]
	
	\textbf{(b) Достаточность (\( \Leftarrow \))}.  
	Пусть \( \forall x_1, x_2, y_1, y_2 \in \mathbb{R} \), 
	
	\[
	P\{x_1 \leq X < x_2, \, y_1 \leq Y < y_2\} = P\{x_1 \leq X < x_2\} P\{y_1 \leq Y < y_2\}
	\]
	
	Тогда
	
	\[
	F(x, y) = P\{X < x, Y < y\} = P\{-\infty < X < x, -\infty < Y < y\} =
	\]
	
	\[
	=\text{(при } x_1 = -\infty, x_2 = x, y_1 = -\infty, y_2 = y \text{)} =
	\]
	
	\[
	= P\{-\infty < X < x\} P\{-\infty < Y < y\} = F_X(x) F_Y(y)
	\]
	
	\item Случайные величины \( X \) и \( Y \) независимы
	\(\Leftrightarrow \forall M_1, M_2 \ \text{события} \{ X \in M_1 \} \ \text{и} \{ Y \in M_2 \} \ \text{независимы},\)
	где \( M_1 \), \( M_2 \) -- промежутки или объединения промежутков в \( \mathbb{R} \).
	
	\textbf{Доказательство.} Является обобщением свойств 1 и 2.
	
	\item Если \( X \) и \( Y \) — дискретные случайные величины, то $X, Y \ \text{независимы} \Leftrightarrow p_{ij} \equiv P_X(x_i) P_Y(y_j)$,\newline
	где \( p_{ij} = P\{ (X, Y) = (x_i, y_j) \} \), \( P_X(x_i) = P\{ X = x_i \} \), \( P_Y(y_j) = P\{ Y = y_j \} \).
	
	\textbf{Доказательство.}
	
	\textbf{(a) Достаточность (\( \Leftarrow \))}.  
	Достаточность была доказана выше, в рассуждениях перед определением независимых случайных величин.
	
	\textbf{(b) Необходимость (\( \Rightarrow \))}.  
	Необходимость студентам предлагается доказать самостоятельно.
	
	\item Если \( X \) и \( Y \) — непрерывные случайные величины, то $X, Y \ \text{независимы} \Leftrightarrow f(x, y) \equiv f_X(x) f_Y(y)$.
	
	\textbf{Доказательство.}
	
	\textbf{(a) Необходимость (\( \Rightarrow \))}.  
	Пусть \( F(x, y) \equiv F_X(x) F_Y(y) \). По свойству двумерной плоскости:
	
	\[
	f(x, y) = \frac{\partial^2 F(x, y)}{\partial x \, \partial y} = \frac{\partial}{\partial x} \frac{\partial}{\partial y} [F_X(x) F_Y(y)] = \frac{d F_X(x)}{dx} \cdot \frac{d F_Y(y)}{dy} = f_X(x) f_Y(y)
	\]
	
	\textbf{(b) Достаточность (\( \Leftarrow \))}.  
	Пусть \( f(x, y) = f_X(x) f_Y(y) \). Тогда
	
	\[
	F(x, y) = \int_{-\infty}^{x} dt \int_{-\infty}^{y} f(t, v) \, dv =
	\int_{-\infty}^{x} dt \int_{-\infty}^{y} f_X(t) f_Y(v) \, dv = \underbrace{\int_{-\infty}^{x} f_X(t) \, dt}_{F_X(x)} \underbrace{\int_{-\infty}^{y} f_Y(v) \, dv}_{F_Y(y)} = F_X(x) F_Y(y)
	\]
\end{enumerate}


Случайные величины \( X_1, \dots, X_n \), заданные на одном вероятностном пространстве, называются:
\begin{itemize}
	\item \textbf{Попарно независимыми}, если \( X_i \) и \( X_j \) независимы при \( i \neq j \);
	\item \textbf{Независимыми в совокупности}, если $
	F(x_1, \dots, x_n) = F_{X_1}(x_1) \cdot \dots \cdot F_{X_n}(x_n),$
	где \( F \) — совместная функция распределения случайных величин \( X_1, \dots, X_n \) ($\equiv$ функция распределения случайного вектора \( (X_1, \dots, X_n) \)); \( F_{X_i} \) — маргинальные функции распределения случайных величин \( X_i \), \( i = 1, \dots, n \).
\end{itemize}

\section{Понятие условного распределения случайной величины. Сформулировать определение условного ряда распределения компоненты двумерного дискретного случайного вектора. Привести рассуждения, приводящие к такому определению. Сформулировать определение условной плотности распределения компоненты двумерного непрерывного случайного вектора. Сформулировать критерии независимости случайных величин в терминах условных распределений}

\textbf{Условное распределение} случайного вектора $(X, Y)$ описывает распределение одной из случайных величин (или их совокупности) при фиксированном значении другой.

\subsubsection*{Случай дискретного случайного вектора}

Пусть выполняются следующие условия.

\begin{enumerate}
	
	\item $(X,Y)$ -- дискретный случайный вектор;
	\item $X \in \{x_1, ..., x_m\}$, $Y \in \{y_1, ..., y_n\}$;
	\item $p_{ij} = P\{(X,Y) = (x_i, y_i)\}, i = \overline{1; m}, j = \overline{1; n}$.
	
	$P_{X_i} = P\{X = x_i\}, i = \overline{1; m}$
	
	$P_{Y_j} = P\{Y = y_j\}, j = \overline{1; n}$
	
	\item Известно, что $Y = y_j$ для некоторого фиксированного $j$.
\end{enumerate}
Тогда 
\begin{align*}
	P\{X = x_i \,|\, Y = y_j\} &= 
	\left( \text{из определения условной вероятности} \right) = \\
	&= \frac{P(\{X = x_i\} \cap \{Y = y_j\})}{P(Y = y_j)} = 
	\frac{P((X, Y) = (x_i, y_j))}{P(Y = y_j)} = 
	\frac{p_{ij}}{P_Y}.
\end{align*}
Условная вероятность того, что случайная величина $Y$ приняла значение $y_j$ при условии $X = x_i$ определяется аналогично.

Набор вероятностей $P\{X = x_i \,|\, Y = y_j\}, i = \overline{1; m}$ для данного фиксированного $j$ называется условным распределением случайной величины $X$ при условии $Y = y_j$ (аналогично для случайной величины $Y$ при условии $X = x_i$ для данного фиксированного $i$). По этому набору можно составить ряд распределения, представленного таблицей значений.

\subsubsection*{Случай непрерывного случайного вектора}

В случае непрерывного случайного вектора $(X, Y)$.

Условной плотностью распределения случайной величины $X$ при условии $Y = y$ называется функция

\begin{align*}
	f_X(x|Y=y) = \frac{f(x, y)}{f_Y(y)},
\end{align*}
где $f$ -- совместная плотность распределения случайных величин $X$ и $Y$ (плотность распределения случайного вектора $(X, Y)$), $f_Y$ -- маргинальная плотность распределения случайной величины $Y$.

Аналогичным образом определяется условная плотность распределения случайной величины $Y$ при условии $X = x$.

\subsubsection*{Критерии независимости случайных величин в терминах условных распределений}

\begin{enumerate}
	
	\item Пусть $(X, Y)$ -- двумерный случайный вектор. Тогда следующие условия эквивалентны: 
	
	\begin{itemize}
		\item $X, Y$ -- независимые.
		\item $F_X(x | Y=y) \equiv F_X(x)$ для всех $y$, в которых определена $F_X(x|Y=y)$.
		\item $F_Y(y | X=x) \equiv F_Y(y)$ для всех $x$, в которых определена $F_Y(y|X=x)$.
	\end{itemize}
	\item Если $(X, Y)$ -- непрерывный случайный вектор, то следующие условия эквивалентны: 
	\begin{itemize}
		\item $X, Y$ -- независимые.
		\item $f_X(x | Y=y) \equiv f_X(x)$ для всех $y$, в которых определена $f_X(x|Y=y)$.
		\item $f_Y(y | X=x) \equiv f_Y(y)$ для всех $x$, в которых определена $f_Y(y|X=x)$.
	\end{itemize}
	\item Если $(X, Y)$ -- дискретный случайный вектор ($X \in \{x_1, ..., x_m\}$, $Y \in \{y_1, ..., y_n\}$), то следующие утверждения эквивалентны:
	\begin{itemize}
		\item $X, Y$ -- независимые.
		\item $P\{X=x_i | Y=y_j\} \equiv P\{X=x_i\}$ для всех $j=\overline{1, n}$.
		\item $P\{Y=y_j | X=x_i\} \equiv P\{Y=y_j\}$ для всех $i=\overline{1, m}$.
	\end{itemize}
\end{enumerate}


\section{Понятие функции скалярной случайной величины. Доказать теорему о формуле для вычисления плотности $f_Y(y)$ случайной величины $Y=\varphi (X)$, если $X$ – непрерывная случайная величина, а $\varphi$ –- монотонная непрерывно дифференцируемая функция. Сформулировать аналогичную теорему для кусочно-монотонной функции $\varphi$}

Пусть:
\begin{enumerate}
	\item $X$ -- некоторая случайная величина;
	\item $\varphi: \mathbb{R} \rightarrow \mathbb{R}$ -- некоторая известная функция.
\end{enumerate}

Тогда $\varphi (X) = Y$ -- некоторая случайная величина.

Если $X$ -- \textbf{непрерывная} случайная величина, то в зависимости от функции $\varphi$ случайная величина $Y = \varphi(X)$ может быть как непрерывной случайной величиной, так и дискретной или смешанного типа.

\subsection*{Теорема}

Пусть
\begin{enumerate}
	\item $X$ -- непрерывная случайная величина;
	\item $\varphi: \mathbb{R} \to \mathbb{R}$;
	\item $\varphi$ монотонна и непрерывно дифференцируема;
	\item $\psi$ -- функция, обратная к $\varphi$ (так как $\varphi$ -- монотонная, то существует $\psi = \varphi^{-1}$);
	\item $Y = \varphi(X)$.
\end{enumerate}

Тогда
\begin{enumerate}
	\item $Y$ также является непрерывной случайной величиной;
	\item Плотность вероятности $f_Y(y)$ задается следующим образом: 
	
	\begin{align*}
		f_Y(y) = f_X(\psi(y)) \cdot\left|\psi'(y)\right|.
	\end{align*}
\end{enumerate}

\subsection*{Доказательство}

\begin{enumerate}
	\item $F_Y(y) = P\{Y < y\} = P\{\varphi(X) < y\}$
	\begin{enumerate}
		\item Если $\varphi$ -- монотонно возрастающая функция, то $\varphi(X) < y \iff X < \varphi ^{-1}(y) = \psi(y)$;
		\item Если $\varphi$ -- монотонно убывающая функция, то $\varphi(X) < y \iff X > \varphi ^{-1}(y) = \psi(y)$;
	\end{enumerate}
	\item В случае случая a, $F_Y(y) = P\{X < \psi(y)\} = F_X(\psi(y))$; в случае b $F_Y(y) = P\{X > \varphi(y)\} = 1 - P\{X \preceq \psi(y)\} = \langle X \text{-- непрерывна} \rangle = 1 - P\{X < \psi(y)\} = 1 - F_X(\psi(y))$;
	\item 
	
	\[
	f_Y(y) = F_Y'(y) = 
	\begin{cases} 
		\frac{d}{dy} [F_X(\psi(y))] = F'_X(\psi(y)) \cdot \psi'(y), & \text{если a} \\
		\frac{d}{dy} [1 - F_X(\psi(y))] = -F'_X(\psi(y)) \cdot \psi'(y), & \text{если b}
	\end{cases}
	= f_X(\psi(y)) \cdot |\psi'(y)|.
	\]
	
\end{enumerate}

\subsection*{Теорема}

Пусть
\begin{enumerate}
	\item $X$ -- непрерывная случайная величина;
	\item $\varphi: \mathbb{R} \to \mathbb{R}$ является кусочно-монотонной функцией, имеющей n интервалов монотонности;
	\item $\varphi$ дифференцируема;
	\item Для данного $y \in \mathbb{R} , x_1 = x_1(y), ..., x_k = x_k(y) (k \leq n)$ -- это все решения уравнения $y = \varphi(x)$, принадлежащие интервалам $I_1, ..., I_k$ монотонности функции $\varphi$.
\end{enumerate}

Тогда для данного в последнем условии значения $y$:
\[
f_Y(y) = \sum_{j = 1}^{k} f_X (\psi_j(y)) \cdot |\psi_j'(y)|,
\]

где $\psi_j(y)$ -- функция, обратная к $\varphi(x)$ на интервале $I_j, j = \overline{1, k}$.

\section{Понятие скалярной функции случайного вектора. Обосновать формулу для вычисления функции распределения случайной величины Y , функционально зависящей от случайных величин X1 и X2, если (X1, X2) – непрерывный случайный вектор. Доказать теорему о формуле свертки}

\subsection*{Скалярные функции случайного вектора}

Пусть:
\begin{enumerate}
	\item $(X_1,X_2)$ -- двумерный случайный вектор.
	\item $\varphi: \mathbb{R}^2 \to \mathbb{R}$.
	\item $Y = \varphi(X_1, X_2)$ -- некоторая одномерная случайная величина.
\end{enumerate}

\subsection*{Случай непрерывного случайного вектора}

Если $(X_1, X_2)$ -- непрерывный случайный вектор, то функцию распределения случайной величины $Y = \varphi(X_1, X_2)$ можно найти по формуле:

\begin{align*}
	F_Y(y) = \iint\limits_{D(y)} f(x_1, x_2) \, dx_1 dx_2,
\end{align*}
где $f$ -- совместная плотность распределения случайных величин $X_1$ и $X_2$, $D(y) = \{(x_1, x_2):\varphi(x_1, x_2)<y\}$.

Пусть есть двумерный случайный вектор $(X_1, X_2)$, и:
\begin{enumerate}
	\item $(X_1, X_2)$ -- непрерывный случайный вектор;
	\item $X_1, X_2$ -- независимы;
	\item $Y = X_1 + X_2$;
	\item $f(x_1, x_2)$ -- совместная плотность распределения.
\end{enumerate}

\begin{wrapfigure}{r}{0.3\textwidth}
	\includegraphics[width=\linewidth]{img/1.png}
\end{wrapfigure}  

Тогда $f_Y(y) = \int_{-\infty}^{+\infty} f_{X_1}(x_1)f_{X_2}(y-x_1) \, dx_1$ -- \textbf{функция свертки}.

\textbf{Доказательство}. $F_Y(y) = P\{Y<y\} = P\{X_1 + X_2 < y\} = \int \int_{D(y)} f(x_1, x_2) \, dx_1 \,dx_2 = \int_{-\infty}^{+\infty} \, dx_1 \int_{-\infty}^{y-x_1} f(x_1, x_2) \,dx_2 = \zigzagline x_1, x_2 \text{-- независимы}, f(x_1, x_2) = f_{X_1}(x_1)f_{X_2}(x_2) \zigzagline = \int_{-\infty}^{+\infty} \, dx_1 f_{X_1}(x_1) \int_{-\infty}^{y-x_1} f_{X_2}(x_2) \,dx_2 = \int_{-\infty}^{+\infty} \, dx_1 f_{X_1}(x_1) F_{X_2}(y-x_1)$. Продифференцируем: $f_Y(y) = \frac{d}{dy}(F_Y(y)) = [\int_{-\infty}^{+\infty} f_{X_1}(x_1) F_{X_2}(y-x_1) \, dx_1]' = \zigzagline \frac{d}{dy}(F_{X_2}(y-x_1)) = f_{X_2}(y-x_1) \zigzagline = \int_{-\infty}^{+\infty} f_{X_1}(x_1) f_{X_2}(y-x_1) \, dx_1$.

\section{Сформулировать определение математического ожидания для дискретной и непрерывной случайных величин. Механический смысл математического ожидания. Доказать свойства математического ожидания. Записать формулы для вычисления математического ожидания функции случайной величины и случайного вектора}

\begin{wrapfigure}{l}{0.5\textwidth}
	\includegraphics[width=\linewidth]{img/2.png}
\end{wrapfigure}  

Пусть $X$ -- \textbf{дискретная} случайная величина. \textbf{Математическое ожидание} (среднее значение) случайной величины $X: M[X] = \sum_{i} x_ip_i,$ где $p_i = P\{X=x_i\}$, $i$ пробегает все номера элементов конечного множества значений случайной величины.

\begin{wrapfigure}{r}{0.5\textwidth}
	\includegraphics[width=\linewidth]{img/3.png}
\end{wrapfigure}  

Пусть $X$ -- \textbf{непрерывная} случайная величина, $f_X(x)$ -- плотность распределения. \textbf{Математическое ожидание} (среднее значение) случайной величины $X: M[X] = \int_{-\infty}^{+\infty} xf(x)\, dx$.


\textbf{Свойства}:
\begin{enumerate}
	\item Если $P\{X = x_0\} = 1$ (т.е. если $X$ фактически не является случайной), то $MX = x_0$;
	\item $M[aX + b] = a \cdot MX + b$;
	\item $M[X_1 + X_2] = MX_1 + MX_2$;
	\item Если $X_1, X_2$ -- независимы, то $M[X_1X_2] = (MX_1)(MX_2)$.
\end{enumerate}

\textbf{Доказательства}:
\begin{enumerate}
	\item Ряд распределения:
	\begin{tabular}{|>{\columncolor[gray]{0.8}}c|c|}
		\hline
		X & $x_0$ \\ \hline
		$P$ & $1$ \\ \hline
	\end{tabular}
	
	По определению: $MX = \sum_i p_ix_i = 1 \cdot x_0 = x_0$;
	
	\item Докажем для случая непрерывной случайной величины:
	
	\begin{align}
		M[aX + b] &= \langle \varphi(x) = ax + b; aX + b \text{ -- непрерывная случайная величина} \rangle \notag \\
		&= \int_{-\infty}^{+\infty} (ax+b)f(x) \, dx = a \int_{-\infty}^{+\infty} x f(x) \, dx + b \int_{-\infty}^{+\infty} f(x) \, dx \notag \\
		&= a \cdot MX + b \notag;
	\end{align}
	
	\item Доказательство для дискретного случая. Элементы $X_1$ обозначаются индексами $i$, пробегающими множество $I$; для $X_2$ используются $j$ и $J$. Запись о:
	
	\begin{align}
		M[X_1 + X_2] &= \langle \varphi(x_1, x_2) = x_1 + x_2 \rangle \notag \\
		&= \sum_{i \in I} \sum_{j \in J} (x_{1, i} + x_{2, j})p_{ij} =  \sum_{i \in I} \sum_{j \in J} x_{1, i}p_{ij} +  \sum_{i \in I} \sum_{j \in J} x_{2, j}p_{ij} \notag \\
		&= \sum_{i \in I} x_{1, i} \sum_{j \in J} p_{ij} + \sum_{j \in J} x_{2, j} \sum_{i \in I} p_{ij} \notag \\
		&= MX_1 + MX_2 \notag;
	\end{align}
	
	\item Докажем для непрерывных случайных величин:
	
	\begin{align}
		M[X_1X_2] &= \langle \varphi(x_1, x_2) x_1x_2 \rangle = \int \int_{R^2} x_1x_2f(x_1, x_2) \, dx_1 \, dx_2 \notag \\
		&= \langle X_1, X_2 \text{ -- независимы} \Rightarrow f(x_1, x_2) = f_{X_1}(x_1)f_{X_2}(x_2) \rangle \notag \\
		&= \int_{-\infty}^{+\infty} \, dx_1 \int_{-\infty}^{+\infty} x_1x_2f_{X_1}(x_1)f_{X_2}(x_2) \, dx_2 = (\int_{-\infty}^{+\infty} x_1f_{X_1}(x_1) \, dx_1) (\int_{-\infty}^{+\infty} x_2f_{X_2}(x_2) \, dx_2) \notag \\
		&= (MX_1) (MX_2) \notag.
	\end{align}
	
\end{enumerate}

\subsection*{Формулы для вычисления математического ожидания}

\begin{enumerate}
	\item $X$ -- случайная величина, $\varphi: \mathbb{R} \rightarrow \mathbb{R}$:
	\begin{itemize}
		\item $M[\varphi(X)] = \sum_{i} \varphi(x_i)p_i$, если $X$ -- дискретная случайная величина;
		\item}$M[\varphi(X)] = \int_{-\infty}^{+\infty} \varphi(x)f(x) \, dx$, если $X$ -- непрерывная случайная величина, $f(x)$ -- плотность;
\end{itemize}
\item $\vec{X} = (X_1, X_2)$ -- случайный вектор, $\varphi: \mathbb{R}^2 \rightarrow \mathbb{R}, Y = \varphi(X_1, X_2)$. $p_{ij} = P_i\{(X_1, X_2) = (x_{1, i}, x_{2, j})\}$:
\begin{itemize}
	\item $M[\varphi(X_1, X_2)] = \sum_{i, j} \varphi (x_{1, i}, x_{2, j})p_{ij}$, если $\vec{X}$ -- дискретный вектор;
	\item $M[\varphi(X_1, X_2)] = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} \varphi(x_1, x_2)f(x_1, x_2) \, dx_1 \, dx_2$, где $f(x_1, x_2)$ -- совместная плотность непрерывного случайного вектора $\vec{X}$.
\end{itemize}
\end{enumerate}


\section{Сформулировать определение дисперсии случайной величины. Механический смысл дисперсии. Доказать свойства дисперсии. Понятие среднеквадратичного отклонения случайной величины}

\textbf{Дисперсией} случайной величины $X$ называется $DX = M[(X-m)^2],$ где $m=MX$.

Если $X$ -- \textbf{дискретная} случайная величина, то $DX = \sum_{i} (x_i - m)^2 p_i$, где $p_i = P\{X=x_i\}$. Если  $X$ -- \textbf{непрерывная} случайная величина, то $DX = \int_{-\infty}^{+\infty} (x-m)^2f(x) \, dx$, где $f$ -- функция плотности случайной величины $X$.

\textbf{Механический смысл дисперсии:} дисперсия является моментом инерции вероятностной массы относительно точки $m=MX$, т.е. характеризует <<разброс>> вероятностной массы относительно математического ожидания этой случайной величины. Чем больше $D$, тем больше <<разброс>>.

\textbf{Свойства}:
\begin{enumerate}
\item для любого случайного вектора $X: DX \geq 0$;
\item если $P\{X=x_0\} = 1,$ то $DX = 0$;
\item $D[aX+b] = a^2DX,      a, b = const$;
\item $D[X] = M[X^2] - (MX)^2$;
\item если $X_1, X_2$ -- независимые случайные величины, то $D[X_1 + X_2] = D[X_1] + D[X_2]$.
\end{enumerate}

\textbf{Доказательства}:
\begin{enumerate}
\item $DX = MY$, где $Y = (X - m)^2$. Т.к. $Y \geq 0$, то следует, что $DX = MY \geq 0$;
\item ...
\begin{tabular}{|>{\columncolor[gray]{0.8}}c|c|}
	\hline
	X & $x_0$ \\ \hline
	$P$ & $1$ \\ \hline
\end{tabular}

Математическое ожидание $MX = m = x_0$. Дисперсия $DX = \sum_{i} (x_i - m)^2p_i = (x_0 = x_0)^2 \cdot 1 = 0$;	
\item

\begin{align}
	D[aX + b] &= M[[(aX+b) - M(aX+b)]^2] = M[[aX + b - a \cdot MX - b]^2]  \notag \\
	&= M[(a(X-MX))^2] = a^2M[(X -MX)^2] \notag \\
	&= a^2DX \notag;
\end{align}

\item Обозначим $m = MX$, тогда:
\begin{align}
	DX &= M[(X=m)^2] = M[X^2-2mX +m^2] = M[X^2]-2m\cdot M[X]+m^2 \notag \\
	&= M[X^2]-m^2 \notag;
\end{align}

\item 
\begin{align}
	D(X_1 + X_2) &= \langle \text{по свойству 4} \rangle = M[(X_1 + X_2)^2] - (M(X_1 + X_2))^2 \notag \\
	&= M[X_1^2] + M[X_2^2] + 2M[X_1X_2] - (MX_1)^2 - (MX_2)^2 - 2MX_1 \cdot MX_2 = \notag \\
	&=  \langle X_2, X_2 \text{ -- независимые, тогда } M[X_1X_2] = MX_1 \cdot MX_2 \rangle \notag \\
	&= (M[X_1^2] - (MX_1)^2) + (M[X_2^2] - (MX_2)^2) \notag \\
	&= DX_1 + DX_2 \notag.
\end{align}

\end{enumerate}

$DX$ имеет размерность, равную квадрату размерности случайной величины $X$. Это не всегда удобно на практике, поэтому рассматривают такую числовую характеристику, как среднеквадратичное отклонение.

\textbf{Среднеквадратичным отклонением} случайной величины $X$ называют число $\sigma_X = \sqrt{D[X]}$. 

\section{Сформулировать определение математического ожидания и дисперсии. Записать законы распределения биномиальной, пуассоновской, равномерной, экспоненциальной и нормальной случайной величин. Найти математические ожидания и дисперсии этих случайных величин}

Пусть $X$ -- \textbf{дискретная} случайная величина. \textbf{Математическое ожидание} (среднее значение) случайной величины $X: M[X] = \sum_{i} x_ip_i,$ где $p_i = P\{X=x_i\}$, $i$ пробегает все номера элементов конечного множества значений случайной величины.

Пусть $X$ -- \textbf{непрерывная} случайная величина, $f_X(x)$ -- плотность распределения. \textbf{Математическое ожидание} (среднее значение) случайной величины $X: M[X] = \int_{-\infty}^{+\infty} xf(x)\, dx$.

\textbf{Дисперсией} случайной величины $X$ называется $DX = M[(X-m)^2],$ где $m=MX$.

\subsection*{Биноминальная случайная величина}

Говорят, что случайная величина $X$ имеет биноминальное распределение с параметром $n \in \mathbb{N}$ и $p \in (0, 1)$, если она принимает значения $0, 1, ..., n$ с вероятностями: $P\{X = k\} = C_n^k \cdot p^k \cdot q^{n-k}, k = \overline{0, n}, q = 1 - p.$ Обозначается: $X \sim B(n, p)$.

\[
MX = M[\sum_{i = 1}^{n} X_i] = \sum_{i = 1}^{n} MX_i = np
\]

\[
DX = D[\sum_{i = 1}^{n} X_i] = \langle X_i \text{ независимы } \rangle = \sum_{i = 1}^{n} DX_i = npq.
\]

\subsection*{Пуассоновская случайная величина}

Говорят, что случайная величина $X$ распределена по закону Пуассона с параметром $\lambda > 0$, если она принимает значения $0, 1, 2, ...$ с вероятностями: $P\{X = k\} = \frac{\lambda ^ k}{k!}\cdot e^{-\lambda}, k \in \{0, 1, 2, ...\}$. Обозначается: $X \sim \text{П}(\lambda)$.

\begin{align}
MX &= \sum_{k = 0}^{\infty} k \frac{\lambda^k}{k!} e^{-\lambda} = e^{-\lambda} \sum_{k=1}^{\infty}k \frac{\lambda^k}{k!} = e^{-\lambda} \sum_{k=1}^{\infty} \frac{\lambda^{k-1} \lambda}{(k-1)!} \notag \\
&= \lambda e^{-\lambda} \sum_{k=1}^{\infty} \frac{\lambda^{k-1}}{(k-1)!} = \langle i = k -1 \rangle = \lambda e^{-\lambda} \sum_{i=0}^{\infty} \frac{\lambda^i}{i!} \notag \\
&= \lambda \notag.
\end{align}

Дисперсия выражается как $DX = M[X^2] - (MX)^2$.

\[
MX^2 = \sum_{k = 0}^{\infty} k^2 \frac{\lambda^k}{k!} e^{-\lambda} = ... = \lambda^2 + \lambda. \text{ Тогда } DX = \lambda.
\].


\subsection*{Равномерное распределение}

Говорят, что случайная величина $X$ имеет равномерное распределение на отрезке $[a, b]$, если она является непрерывной случайной величиной с функций плотности распределения: 

\[
f(x) = 
\begin{cases} 
c, & x \in [a, b] \\
0, & \text{иначе}
\end{cases}
, \text{где } c = const.
\]

Обозначается: $X \sim R(a, b)$.

$X \sim R(0, 1)$.

\[
f(x) = 
\begin{cases} 
\frac{1}{b-a}, & x \in (a, b) \\
0, & \text{иначе}
\end{cases}
\]

\[
MX = \int_{-\infty}^{\infty} xf(x) \, dx = \frac{1}{b-a} \int_a^b x \, dx = \frac{1}{2(b-a)}(b^2-a^2) = \frac{a+b}{2}
\]

\begin{align}
DX &= \int_{-\infty}^{+\infty} (x-\frac{a+b}{2}) f(x) \, dx = \frac{1}{b-a} \int_a^b (x-\frac{a+b}{2})^2 \, dx \notag \\
&= \frac{1}{3(b-a)}(x-\frac{a+b}{2})^3 \left| \substack{a \\ \\ \\ b} \right = \frac{1}{3(b-a)} (\frac{(b-a)^3}{8} - \frac{(a-b)^3}{8}) = \frac{(b-a)^3}{12(b-a)} \notag \\
&= \frac{(b-a)^2}{12} \notag.
\end{align}

\subsection*{Экспоненциальное распределение}

Говорят, что случайная величина $X$ распределена по закону с параметром $\lambda > 0$, если $X$ является непрерывной случайной величиной, функция плотности которой имеет вид:

\[
f(x) = 
\begin{cases} 
\lambda e^{-\lambda x}, & x \geq 0 \\
0, & \text{иначе.}
\end{cases}
\]

Обозначается: $X \sim Exp(\lambda)$.

\begin{align}
MX &= \int_{-\infty}^{+\infty} xf(x)x = \lambda \int_{0}^{+\infty} xe^{-\lambda x} \, dx = -\int_{0}^{+\infty} x \, de^{-\lambda x} \notag \\
&= -xe^{-\lambda x} \left| \substack{+\infty \\ \\ \\ 0} \right + \int_{0}^{+\infty} e^{-\lambda x} \, dx = -\frac{1}{\lambda} e^{-\lambda x} \left| \substack{+\infty \\ \\ \\ 0} \right \notag \\
&= \frac{1}{\lambda} \notag.
\end{align}

$DX = M[X^2] - (MX)^2$,

\begin{align}
M[X^2] &= \int_{-\infty}^{+\infty} x^2 f(x) \, dx = \lambda \int_{0}^{+\infty} x^2 e^{-\lambda x} \, dx = -\int_{0}^{+\infty} x^2 \, de^{-\lambda x} = -x^2e^{-\lambda x} \left| \substack{+\infty \\ \\ \\ 0} \right + 2 \int_{0}^{+\infty} xe^{-\lambda x} \, dx \notag \\
&= \frac{2}{\lambda^2} \notag.
\end{align}

Таким образом, $DX = \frac{2}{\lambda^2} - (\frac{1}{\lambda})^2 = \frac{1}{\lambda^2}$.

\subsection*{Нормальное распределение}

Говорят, что случайная величина $X$ имеет нормальное распределение с параметрами $m$ и $\sigma ^2$, если $X$ -- является непрерывной случайной величиной, функция плотности которой имеет вид:

\[
f(x) =  \frac{1}{\sqrt{2 \pi} \cdot \sigma} \cdot e^{-\frac{(x-m)^2}{2\sigma ^2}}, x \in \mathbb{R}.
\]

Обозначается: $X \sim N(m, \sigma ^2)$.

\begin{align}
MX &= \int_{-\infty}^{+\infty} xf(x) \, dx = \frac{1}{\sigma \sqrt{2 \pi}} \int_{-\infty}^{+\infty} xe^{-\frac{(x-m)^2}{2 \sigma^2}} \, dx = \langle x-m= t \rangle \notag \\
&= \frac{1}{\sigma \sqrt{2 \pi}} \int_{-\infty}^{+\infty} (t+m) e^{-\frac{t^2}{2\sigma^2}} \, dt =  \frac{1}{\sigma \sqrt{2 \pi}} \int_{-\infty}^{+\infty} te^{-\frac{t^2}{2\sigma^2}} \, dt + m \cdot  \frac{1}{\sigma \sqrt{2 \pi}} \int_{-\infty}^{+\infty} e^{-\frac{t^2}{2\sigma^2}} \, dt \notag \\
&= m.
\end{align}

\begin{align}
DX &= M[(X-MX)^2] = \int_{-\infty}^{+\infty} (x-m)^2 f(x) \, dx = \frac{1}{\sigma \sqrt{2 \pi}} \int_{-\infty}^{+\infty} (x-m)^2e^{-\frac{(x-m)^2}{2 \sigma^2}} \, dx \notag \\
&= \langle \frac{x-m}{\sigma} = t, dx = \sigma \, dt \rangle = \frac{\sigma^2}{\sqrt{2 \pi}} \int_{-\infty}^{+\infty} t^2 e^{-\frac{t^2}{2}} \, dt =\frac{\sigma^2}{2\sqrt{2 \pi}} \int_{-\infty}^{+\infty} te^{\frac{t^2}{2}} \, dt^2 \notag \\
&= - \frac{\sigma^2}{\sqrt{2 \pi}} \int_{-\infty}^{+\infty} t \, de^{-\frac{t^2}{2}} \, dt^2 = \langle \text{ по частям } \rangle = -\frac{\sigma^2}{\sqrt{2 \pi}} te^{-e\frac{t^2}{2}}  \left| \substack{+\infty \\ \\ \\ - \infty} \right + \sigma^2 \cdot \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{+\infty} e^{-\frac{t^2}{2}} \, dt \notag \\
&= \sigma^2.
\end{align}

\section{Сформулировать определение ковариации и записать формулы для ее вычисления в случае дискретного и непрерывного случайных векторов. Доказать свойства ковариации}

Ковариация является числовой характиристикой случайного вектора. Пусть $(X_1, X_2)$ -- двумерный случайный вектор. $Ковариацией$ случайной величины $X_1$ и $X_2$ называется число $cov(X_1, X_2) = M[(X_1 - m_1)(X_2 - m_2)],$ где $m_i = MX_i, i = \overline{1, 2}$.

Если $X_1, X_2$ - дискретный случайные величины, то $cov(X_1, X_2) = \sum_{i_1, i_2}(x_{1, i_1}-m_1)(x_{2, i_2}-m_2)p_{i_1i_2},$ где $p_{i_1i_2} = P\{(X_1, X_2) = (x_{1, i_1}, x_{2, i_2})\}$.

Если $X_1, X_2$ - непрерывные случайные величины, то $cov(X_1, X_2) = \int \int_{\mathbb{R}} (x_1 - m_1)(x_2 - m_2) f(x_1, x_2) \, dx_1 \,dx_2$, где $f$ -- совместная плотность распределения $X_1$ и $X_2$.

\textbf{Свойства}:
\begin{enumerate}
\item $D[X+Y] = DX + DY + 2cov(X, Y)$;
\item $cov(X, X) = DX$;
\item если $X, Y$ -- независимы, то $cov(X, Y) = 0.$ Обратное не верно;
\item $cov(a_1X + b_1, a_2Y + b_2) = a_1a_2cov(X, Y)$;
\item $|cov(X, Y)| \leq \sqrt{DX \cdot DY}$, причем $|cov(X, Y)| = \sqrt{DX \cdot DY} \equiv$ случайные величины $X$ и $Y$ связаны линейной зависимостью;
\item $cov(X, Y) = M[XY] - (MX)(MY)$.
\end{enumerate}

\textbf{Доказательства}:
\begin{enumerate}
\item 
\begin{align}
	D(X+Y) &= M[((X+Y) - M[X+Y])^2] = \langle MX = m_1, MY = m_2 \rangle = M[((X-m_1) - M[Y-m_2])^2] \notag \\ 
	&= M[(X-m_1)^2] + M[(Y-m_2)^2] + 2M[(X-m_1)(Y-m_2)] = \notag \\
	&= DX + DY + 2cov(X, Y) \notag;
\end{align}

\item $cov(X, X) = M[(X-m)(X-m)] = M[(X-m)^2] = DX$;
\item 
\begin{align}
	cov(X, Y) &= M[(X-m_1)(Y-m_2)] = \langle X, Y \text{ -- независимые } \Rightarrow \notag \\
	& (X-m_1) \text{ и } (Y-m_2) \text{ тоже независимые } \rangle = [M(X-m_1)][M(Y-m_2)] \notag \\ 
	&= 0\notag;
\end{align}

\item 
\begin{align}
	cov(a_1X + b_1, a_2X + b_2) &=  M[[a_1X + b_1 - M(a_1X + b_1)] \cdot [a_2X+b_2-M(a_2X + b_2)]] \notag \\ 
	&= M[[a_1X + b_1 - a_1m_1 -b_1][a_2X+b_2 -a_2m_2 - b_2]] \notag \\
	&= M[a_1a_2(X_1-MX_1)(X_2 - MX_2)] \notag;
\end{align}

\item
\begin{enumerate}
	\item Выберем произвольное число $t \in \mathbb{R}$. Рассмотрим случайную величину $Z(t) = tX - Y$. Тогда $D[Z(t)] = D[tX - Y] = \langle \text{ свойство 1 + свойство дисперсии } \rangle = t^2DX + DY - 2t \cdot cov(X, Y) = DX \cdot t^2 - 2t \cdot cov(X, Y) + DY \text{ -- квадратный трехчлен относительно } t$. Так как $D[X(t)] \geq 0$, следовательно, трехчлен должен быть параболой вверх, т.е. дискриминант $D \leq 0$.
	
	\[
	\frac{D}{4} = (cov(X, Y))^2 - DX \cdot DY \leq 0 \Rightarrow |cov(X, Y)| \leq \sqrt{DX \cdot DY};
	\]	
	
	\item Необходимость ($\Rightarrow$). Если $|cov(X, Y)| = \sqrt{DX \cdot DY} \Rightarrow$ дискриминант $=0 \Rightarrow D[Z(t)]$ имеет единственный корень. Обозначим его $t = a \Rightarrow Z(a) = aX - Y$ принимает единственное значение с вероятностью 1, обозначим это значение как $-b \Rightarrow Z(a) = aX - Y = -b \Rightarrow Y=aX+b$; 
	\item Достаточность ($\Leftarrow$). Если $Y = aX + b \Rightarrow Z(a) = -b \Rightarrow D[Z(a)] = 0 \Rightarrow$ дискриминант $= 0 \Rightarrow |cov(X, Y)| = \sqrt{DX \cdot DY}$.
\end{enumerate}

\item
\begin{align}
	cov(X, Y) &=  M[(X - m_1)(Y-m_2)] = M[XY - m_1Y - m_2X + m_1m_2] \notag \\
	&= M[XY] - m_1MY - m_2MX + m_1m_2 \notag \\
	&= M[XY] - m_1m_2 \notag;
\end{align}

\end{enumerate}

\section{Сформулировать определение ковариации и коэффициента корреляции случайных величин. Сформулировать свойства коэффициента корреляции. Сформулировать определения независимых и некоррелированных случайных величин, указать связь между этими свойствами. Понятия ковариационной и корреляционной матриц. Записать свойства ковариационной матрицы}

Ковариация является числовой характиристикой случайного вектора. Пусть $(X_1, X_2)$ -- двумерный случайный вектор. $Ковариацией$ случайной величины $X_1$ и $X_2$ называется число $cov(X_1, X_2) = M[(X_1 - m_1)(X_2 - m_2)],$ где $m_i = MX_i, i = \overline{1, 2}$.

Недостатком ковариации является то, что она имеет размерность равную произведению разностей случайных величин $X$ и $Y$. Часто рассматривают аналогичную безразмерную характеристику, которая называется коэффициентом корреляции случайных величин $X$ и $Y$:

\[
\rho(X, Y) = \rho_{XY} = \frac{cov(X, Y)}{\sqrt{DX \cdot DY}},
\] 
где $DX \cdot DY > 0$.

\textbf{Свойства коэффициента корреляции}:
\begin{enumerate}
\item $\rho_{XX} = 1$;
\item Если $X, Y$ -- независимые, то $\rho_{XY} = 0$;
\item $\rho(a_1X + b_1, a_2Y + b_2) \pm \rho(X, Y),$ причем $\pm$ заменяется на
\begin{itemize}
	\item $+$, если $a_1a_2 < 0$;
	\item $-$, если $a_1a_2 > 0$;
\end{itemize}
\item $\rho_{XY} \leq 1$, причем:
\[
\rho_{XY} =
\begin{cases} 
	1, & \text{когда } Y = aX + b, \text{где } a > 0 \\
	-1, & \text{когда } Y = aX + b, \text{где } a < 0
\end{cases}
\]
\end{enumerate}

Случайные величины $X$ и $Y$ называются некоррелированными, если $cov(X, Y) = 0$.

\(F(x, y) = F_X(x) F_Y(y)\), где \( F \) -- совместная функция распределения \( X \) и \( Y \) ($\equiv$ функция распределения случайного вектора \( (X, Y) \)); \( F_X \), \( F_Y \) -- маргинальные функции распределения случайных величин \( X \) и \( Y \).

Из свойства 3 ковариации следует, что еслим $X, Y$ -- независимые, то $X, Y$ -- некоррелированные. Обратное неверно.

\textbf{Ковариационной матрицей} случайного вектора $\vec{X}$ называется матрица

\[
\sum_{\vec{X}} = (\sigma_{ij})_{i, j = \overline{1, n}},
\]

где $\sigma_{ij} = cov(X_i, X_j)$.

\textbf{Свойства коэффициента корреляции}:
\begin{enumerate}
	\item $\sigma_{ii} = DX_i$;
	\item $\sum_{\vec{X}} = \sum_{\vec{X}}^{T}$;
	\item Если $\vec{Y} = \vec{X}B + \vec{c}$, где $\vec{Y} = (Y_1, ..., Y_m), \vec{X} = (X_1, ..., X_n), B \in M_{n, m}(\mathbb{R})$ (т.е. $\vec{Y}$ является линейной функцией от вектора $\vec{X}$), то $\sum_{\vec{Y}} = B^T \sum_{\vec{X}} B$;
	\item Матрица $\sum_{\vec{X}}$ является неотрицательной определенной, т.е. $\forall \vec{b} \in \mathbb{R}^w: \vec{b}^T \sum_{\vec{X}} \vec{b} \geq 0$;
	\item Если все компоненты вектора $\vec{X}$ попарно независимы, то $\sum_{\vec{X}}$ -- диагональная матрица.
\end{enumerate}
	
\textbf{Корреляционной матрицей} вектора $\vec{X} = (X_1, ..., X_n)$ называют матрицу

\[
P = (\rho_{ij})_{i, j = \overline{1, n}}, 
\]

где $\rho_{ij} =\rho(X_i, X_j)$.


\section{Понятие условного распределения компоненты двумерного случайного вектора (дискретный и непрерывный случаи). Сформулировать определения значений условного математического ожидания и условной дисперсии. Сформулировать определения условного математического ожидания и условной дисперсии. Записать формулы для вычисления условных математического ожидания и дисперсии для компоненты двумерного нормального вектора}

Пусть $(X, Y)$ -- двумерный случайный вектор. Рассмотрим распределение компоненты $X$ этого вектора при условии, что $Y = y$. Т. к. условное распределение обладает всеми свойствами безусловного распределения, то для него также можно рассмотреть числовые характеристики.

\textbf{Дискретный случай.} $(X, Y)$ -- дискретный случайный вектор. Условное распределение компоненты $X$ при условии $Y = y_j: \pi_{ij} = P\{X = x_i | Y = y_j\} = \frac{p_{ij}}{P_{Y_j}}$. Значением условного математического ожидания случайной величины $X$ при условии $Y = y_j$ называется число $M[X|Y = y_j] = \sum_{i} \pi_{ij} x_i$. Значение условного математического ожидания $M[Y|X = x_j]$ определяется аналогично.

\textbf{Непрерывный случай.} Пусть $(X, Y)$ -- непрерывный случайный вектор. Была определена условная плотность: $f_X(x | Y = y) = \frac{f(x, y)}{f_Y(y)}$. Значением математического ожидания случайной величины $X$ при условии $Y = y$ называют число: $M[X|Y = y] = \int_{-\infty}^{+\infty} x f_X(x | Y = y) \, dx$.

\textbf{Условным математическим ожиданием} случайной величины относительно случайной величины $Y$ называют функцию $g(Y) = M[X|Y]$ которая:
\begin{enumerate}
	\item имеет область определения, совпадающую со множеством значений случайной величины $Y$;
	\item для каждого возможного значения $y$ случайной величины $Y$ значение $g(Y) = M[X|Y = y]$ является значением условного математического ожидания.
\end{enumerate}

Условное математическое ожидание $M[Y|X]$ определяется аналогично.

\textbf{Условной дисперсией} случайной величины $X$ относительно случайной величины $Y$ называют случайную величину $D[X|Y] = M[(X- M[X|Y])^2]$.

Значение условной дисперсии:
\begin{itemize}
	\item для дискретного случайного вектора: $D[X|Y = y_j] = \sum_{i} \pi_{ij} (x_i - M[X|Y = y_j])^2$;
	\item для непрерывного случайного вектора: $D[X|Y = y_j] = \int_{-\infty}^{+\infty} (x - M[X|Y = y_j])^2 f_X(X | Y = y_j) \, dx$.
\end{itemize}

Если $(X, Y)$ -- непрерывный случайный вектор и $\vec{m} = (m_1, m_2)$ и $\sum = \begin{pmatrix}
	\sigma_1^2 & \rho \sigma_1 \sigma_2 \\
	\rho \sigma_1 \sigma_2 & \sigma_2^2
\end{pmatrix},$ тогда:

\begin{itemize}
	\item условное распределение $X$ при $Y = y$ будет нормальным;
	\item $M[X|Y = y] = m_1 + \rho \frac{\sigma_1}{\sigma_2}(y - m_2)$;
	\item $D[X|Y = y] = \sigma_1^2(1 = \rho^2)$.
\end{itemize}

\section{Понятие n-мерного нормального распределения. Сформулировать основные свойства многомерного нормального распределения}

Случайный вектор $(X_1,...,X_n)$ имеет нормальное распределение, если его функция плотности распределения имеет вид: 

$f(x_1,...,x_n)=\tfrac{1}{(\sqrt{2\pi})^n\sqrt{det\sum}}e^{-\tfrac{1}{2}Q(\vec{x}-\vec{m})}$, где

$\vec{ч}=(x_1,...,x_n)$

$\vec{m}=(m_1,...,m_n)$

$Q(\vec{\alpha})=\vec{\alpha}\cdot\sum^{\sim}\vec{\alpha}^T$ квадр форма от $n$ перем., $\sum^{\sim}=\sum^{-1}$

$~\vec{\alpha}=(\alpha_1,...,\alpha_n)$

$\sum$ -- положительно опред. матрица порядка $n$

~

\textbf{Свойства многомерного нормального распределения}
\begin{enumerate}
	\item Если $(x_1,...,x_n)$ -- нормальный случайный вектор, то существует его компонента $x_i\sim N(m_i,\sigma_i^2)$ -- тоже нормальная случайная величина;
	
	\item Пусть $\vec{x}\sim N(\vec{m},\sum)$. Тогда, если $\sum$ диагональная, то случайная величина $x_1,...,x_n$ независимы;
	
	\item Пусть $\vec{x}\sim N(\vec{m},\sum)$ -- $n$-мерный случайный вектор. Тогда $\vec{x}'=(x_1,...,x_{n-1})$ нормальный случайный вектор с $\vec{m}'=(m_1,...,m_{n-1})$ и ковариационной матрицей:
	$\sum'$, которая получена из $\sum$ отбрасыванием последней строчки и столбца;
	
	\item Пусть $\vec{x}\sim N(\vec{m},\sum), ~~ \vec{Y}=\lambda_1x_1+...+\lambda_n x_n+\lambda_0$. Тогда $\vec{Y}$ -- нормальная случайная величина;
	
	\item Пусть $\vec{x}=(x_1,x_2)$ двумерный случайный вектор с $\vec{m}=(m_1,m_2)$ и $\sum = 
	\begin{pmatrix}
		\sigma_1^2 & \rho\sigma_1\sigma_2 \\
		\rho\sigma_1\sigma_2 & \sigma_2^2
	\end{pmatrix}$ Тогда:
	\begin{enumerate}
	\item условное распределение $X$ при условии $Y=y$ будет нормальным;
	\item $M[X|Y=y]=m_1+\rho\tfrac{\sigma_1}{\sigma_2}(y-m_2)$;
	\item $D[X|Y=y]=\sigma_1^2(1-\rho^2)$.
	\end{enumerate}
\end{enumerate}
